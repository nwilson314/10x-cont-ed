## Week 1: Bits, Bytes, and Computer Architecture Basics

### Topic Summary

In Week 1, you will build foundational knowledge of how computer systems execute programs and represent data. We begin with a “zoomed-out” tour of a simple program’s life cycle, from writing C/Odin source code to running machine code on a CPU. (In **CS\:APP Chapter 1**, Bryant and O’Hallaron introduce these major ideas by tracing the life cycle of a simple “hello, world” program – this is our starting point.) You’ll learn how high-level code is translated through **compilation, assembly, and linking** into an executable binary. We’ll then explore how the CPU interprets the resulting machine code: the roles of the **processor**, **memory**, and **registers** in executing instructions stored in memory.

A key focus this week is **data representation** (CS\:APP Chapter 2). You will study how information is encoded as bits – for example, how integers can be represented in **unsigned binary** vs. **two’s complement** form. We’ll examine number ranges and why two’s complement is used for signed integers (e.g. observing that adding two positives can yield a negative in two’s complement arithmetic). You’ll practice converting between binary, hexadecimal, and decimal, and understand concepts like word size, endian-ness (byte ordering), and how characters and instructions are just data interpreted in context. By the end of the week, you should grasp how **“information is bits + context”**, meaning the same 0s and 1s could be data, instructions, text, etc., depending on how we interpret them.

This fundamental knowledge will be crucial as you start designing your CPU simulator. Understanding bits and bytes lays the groundwork for simulating registers and memory. Additionally, knowing the steps from source code to machine code will help you appreciate the purpose of the assembler and emulator you’ll build in upcoming weeks. *This week, take time to absorb these basics.* They may feel abstract now, but they will give you intuition for debugging and designing your simulator later. (For instance, when your simulator fetches an instruction represented in binary, you’ll know exactly how that binary came to be.) Don’t hesitate to ask questions – e.g., “Why use two’s complement instead of sign-magnitude?” or “What exactly does the linker do?” – as these questions will deepen your understanding.

### Learning Objectives (Week 1)

By the end of Week 1, you will be able to:

* **Explain the journey from high-level code to execution:** Describe the four phases of a C program’s compilation (preprocessing, compilation to assembly, assembly to machine code, linking), and outline how a “Hello World” program is loaded and run by the CPU (from disk into memory, then executed by the processor with assistance from the OS).
* **Demonstrate understanding of binary and hex representations:** Convert numbers between decimal, binary, and hexadecimal formats. For example, you should manually compute the 8-bit two’s complement binary for a given signed decimal and vice versa.
* **Understand data types and ranges:** Explain how integers are represented in unsigned and two’s complement form, including the range limitations (e.g. 8-bit two’s complement ranges –128 to +127). You should be able to discuss why two’s complement was chosen (e.g. arithmetic properties and single zero representation).
* **Apply bitwise operations:** Use bitwise shifts and masks to manipulate data at the bit-level. You will write simple code snippets (in Odin or C) that perform operations like extracting a byte from an `int` or toggling specific bits, solidifying your comfort with low-level operations.
* **Describe system architecture at a high level:** Identify the main components of a computer (CPU, memory, cache, bus, I/O) and their roles. For instance, given a high-level description of an instruction, you can trace how the CPU would fetch it from memory, decode it, and execute it. (At this stage, this is a conceptual understanding setting the stage for the detailed pipeline later.)

### Mini-Project – *“Data Representation Playground”*

**Project Description:** This week’s hands-on exercise is a small programming project to reinforce data representation concepts. You will create a simple **Data Conversion Tool** in your preferred language (Odin or C) that does the following:

* Accepts an integer (e.g., 32-bit value) from the user (you can start with reading as a signed decimal).
* Displays the number in **binary** (as a string of bits) and **hexadecimal**. If the number is negative, the tool should use two’s complement notation for the binary output (e.g., print a leading 1 for a negative 32-bit value).
* (Optional bonus) Also accept a hexadecimal input string and output its decimal value, to practice parsing and base conversion in the other direction.

**Why:** Writing this tool will force you to handle binary math and bit operations in code – cementing your understanding of how integers are stored. It also gives practice with control structures and I/O in Odin (or C), warming you up for more complex coding in later weeks. Consider how the computer itself would perform these conversions using shifts and masks; by coding it, you’re mimicking that low-level process.

**Instructions & Tips:** Start by planning how to convert a number to binary. One approach is to use repeated division or bit-shifting. For example, to get the lowest-order bit of an integer `x`, you can compute `x & 1`. Then you can shift `x` right by 1 and repeat, collecting bits. Keep in mind the word size (assume 32 bits unless you want to make it flexible). For hex, you can map 4-bit chunks to a hex digit. If using Odin, remember its syntax for bitwise operations is similar to C. This is also a chance to get familiar with Odin’s basics (or refresh C basics): reading input, using loops, etc. If you get stuck, break the problem down: *Can you isolate one byte of the number?* (Hint: use a mask like 0xFF). How will you handle negative numbers? (Hint: in two’s complement, negative numbers still produce correct binary if you treat the value as unsigned data of the same bit-width).

**Success Criteria:** Your program should correctly output binary and hex representations for a variety of test cases:

* For input `10`, it might output `1010` (binary) and `0xA` (hex).
* For input `-1`, in 32-bit two’s complement it should show `0xFFFFFFFF` (hex) and `11111111 11111111 11111111 11111111` in binary (all 1s).
* For a larger example, input `2025` should match the manual conversion: binary `0b11111101001` (which is 11 bits; you might pad to 32 bits) and hex `0x7E9`.

Test edge cases like the maximum 32-bit signed int (`2147483647` or 0x7FFFFFFF) and minimum (`-2147483648` or 0x80000000) to ensure your tool handles them. (It’s fine if you print the full 32-bit binary string for these.)

As you develop, frequently print intermediate results (e.g., print the binary string as you build it) to debug. This is a simple program, but it’s a chance to practice systematic testing. Try to predict the output for a given input, run the program, and verify. If something looks wrong (say, your binary for a negative number doesn’t look like all 1’s at the start), revisit how two’s complement works. This exercise is as much about learning by discovery as it is about getting the right answer. Enjoy tinkering – change a bit in the binary output and see what decimal value it corresponds to, etc. This curiosity will pay off later when building and debugging your CPU simulator.

### Resources

* **CS\:APP, 3rd Edition – Chapters 1 & 2:** *“A Tour of Computer Systems”* and *“Representing and Manipulating Information.”* These chapters are your primary reading. Chapter 1 provides a big-picture view (including how a “hello, world” program is compiled, loaded, and run). Chapter 2 dives into binary representation, covering hex notation, two’s complement, and bit operations. Focus on sections 2.1 and 2.2 for integer representations, and 2.3 for integer arithmetic. (Skim floating-point sections for now unless you’re curious – we won’t need floats for our simulator).
* **Patterson and Hennessy, *Computer Organization and Design*** (optional): Chapter 1 of P\&H also covers data representation and the basics of computer architecture. If you have access, the sections on number representations and the overview of a simple MIPS system can reinforce the concepts from CS\:APP. This is supplementary – use it if you want another perspective or more practice problems.
* **GeeksforGeeks – *“Compiling a C Program: Behind the Scenes”***: A concise online article explaining the stages of C program compilation. This is a handy reference to solidify your understanding of how source code becomes an executable. Since you’re comfortable with C, skim this to ensure you can outline what happens at each step (preprocessor -> compiler -> assembler -> linker) and what files each produces (e.g., object files, executables).
* **OSDev Wiki – *“Assembly”***: Sections of this wiki article explain what an assembler does and the basics of assembly language syntax. While we’ll explore assembly in detail next week, you might find it helpful to read the introduction here. It frames the idea that assembly is a human-readable representation of machine code and that an assembler program translates it into binary. Understanding this process now will give context when you write your own simple assembler in Week 2.
* **Odin Language Documentation** (if using Odin): Since you prefer Odin, ensure you have the Odin documentation handy (available on the official Odin website). Pay attention to how Odin handles basic I/O and any differences from C in bitwise operations or integer types. Odin’s focus on performance and simplicity makes it suitable for this low-level work. If you run into any Odin-specific issues, the community forums or the official docs can be very helpful.

*As you study these resources, take notes on key points – e.g., list out the steps of program execution, or draw a small diagram of how **CPU, RAM, and registers** interact when a program runs. CS\:APP Chapter 1 even mentions caches and operating system roles in passing – don’t worry if not all of that sticks now; you will revisit caches in depth in Week 6. The goal this week is breadth: get comfortable with the *language of computer systems* (bits, bytes, words, CPU, etc.) so that in later weeks we can dive deep into each.*

### Deliverables and Self-Check

**Deliverables:** By the end of the week, you should produce:

* **Code:** The source code of your Data Conversion Tool (the mini-project program). Ensure your code is well-commented, especially to explain any tricky bit-manipulation logic. For example, comment on how you’re constructing the binary string or handling negatives. This will not only help others (or future you) understand your code, but writing comments can clarify your own understanding.
* **Brief Report or Write-up:** A short (around 1 page) summary of what you learned. This can be in the form of answers to the self-check questions below, or a mini-essay touching on them. Focus on articulating concepts in your own words – for instance, you might describe “how two’s complement encoding works” or “the steps the compiler and assembler perform for a simple program.” You might also include a screenshot or sample output from your tool for a couple of test inputs, with an explanation if any results surprised you.
* **Participation/Reflection (informal):** Be prepared to discuss or reflect on the following in our next mentorship session: What part of the journey from code to execution was new to you or most interesting? Was there anything in the reading that you found counter-intuitive (e.g., the idea that adding two positive numbers could overflow to a negative)? Also, share how comfortable you feel with binary/hex math after the mini-project – did writing the conversion tool change how you think about, say, a hex value like 0xFF?

**Self-Check Questions:** Use these to test your understanding and to practice explaining the concepts:

1. **Compilation Stages:** If you compile a simple C program (e.g., `hello.c`) with `gcc -Wall -save-temps hello.c -o hello`, you get intermediate files like `hello.i`, `hello.s`, and `hello.o`. What is contained in each of those files, and what does the compiler do at each stage (preprocessing, compiling to assembly, assembling to object, linking)? *(Explain in your own words. For instance: “The file `hello.s` is the assembly code produced by the compiler from C source, which an assembler then translates to machine code in `hello.o`…”)*

2. **Two’s Complement Basics:** In an 8-bit two’s complement system, what is the binary representation of the decimal number -5? Walk through how you obtain this representation. Then, what decimal value does the binary pattern `1111 0110₂` represent if interpreted as an 8-bit two’s complement number? Show your reasoning. *(This checks that you can convert negatives and interpret binary patterns correctly.)*

3. **Bitwise Operation Thought Experiment:** Suppose you have a 32-bit unsigned integer `x`. You want to extract the lowest 8 bits of `x`. What operation would you use, and what result would you get if `x = 0x12345678`? Similarly, how could you isolate the highest 8 bits? *(Write the answer in terms of bitwise operators or perhaps actual code. This ensures you understand masking and shifting.)*

4. **System Components:** Consider the process of running a program. Can you describe the roles of the **CPU**, **memory (RAM)**, and **registers** during program execution? For example, when the CPU “fetches” an instruction, where does it fetch it from, and how does it know where to fetch from? What happens to that instruction once fetched? *(This is a conceptual check – you might answer with a short narrative: “The CPU’s program counter register holds the address of the next instruction in RAM… it fetches that instruction into a control unit, decodes it, etc.” Even if this feels simple, articulating it prepares you for detailing the pipeline later.)*

5. **Reflection:** Why is it important for a systems programmer (or a 10× engineer-in-training!) to understand how numbers are represented in binary and how code is translated to machine instructions? Can you think of an example where not knowing this could lead to a bug or inefficiency? *(This is to get you thinking about the practical relevance. You might recall things like integer overflow bugs, or how knowing assembly can help optimize critical code.)*

Check your answers against the readings and resources. If you’re unsure about any answer, revisit the relevant section (for instance, CS\:APP Chapter 2 for two’s complement and Chapter 1 for the system overview). Feel free to discuss your answers with me – explaining your reasoning is a great way to solidify it.

### Week 1 Integration to Project Goals

Finally, let’s connect Week 1 to our end goal: the Pipeline-and-Cache CPU Simulator. At first glance, binary numbers and “hello world” program life cycles might seem far from writing a CPU simulator. But the simulator you’ll build is essentially a software model of what the real hardware does. By understanding **machine code** and data at the bit level now, you’ll be ready in Week 2 to define an **instruction set** for your simulator and perhaps write an assembler to produce the machine code your simulator will run. The mental model of “the CPU fetches bytes from memory, decodes them as instructions, and executes actions” starts *here*. This week’s lessons on how a real CPU interprets instructions and uses memory will directly inform how you design your simulator’s fetch-decode-execute cycle. And data representation knowledge will be invaluable when you simulate registers and ALU operations (e.g., adding two 32-bit values and checking for overflow conditions, just like in a real ALU). So, as you wrap up Week 1, you’re not just learning theory – you’re acquiring tools and mental models that will make you a better debugger and designer for the exciting projects to come. Keep up the curiosity and momentum, and remember: I’m here to help clarify and guide you whenever you encounter confusion. Good luck, and enjoy your first week of deep diving “under the hood” of computer systems! 🚀

**Sources:**

* Bryant & O’Hallaron. *Computer Systems: A Programmer’s Perspective, 3rd Ed.* – Chapter 1 introduces how a “hello, world” program is executed across the system; Chapter 2 covers data representation and two’s complement arithmetic.
* GeeksforGeeks – *Compiling a C Program: Behind the Scenes* (explains compilation stages).
* OSDev Wiki – *Assembly* (overview of assembly language and assemblers).
* Odin Programming Language – Official Site (describes Odin’s design as a systems programming language).
